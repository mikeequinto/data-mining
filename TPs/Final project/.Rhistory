## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData)
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData)
predictions
#Compare the true labels of the
#testing instances with the predictions
CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
which(CorrectWrong)
#Get the Number of Correct
#numCorrect <- length(which(CorrectWrong))
#print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
#accuracy <- numCorrect/dim(testData)[1]
#print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData)
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData)
predictions
#Compare the true labels of the
#testing instances with the predictions
##CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
##which(CorrectWrong)
#Get the Number of Correct
#numCorrect <- length(which(CorrectWrong))
#print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
#accuracy <- numCorrect/dim(testData)[1]
#print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData)
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData)
predictions
#Compare the true labels of the
#testing instances with the predictions
##CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
##which(CorrectWrong)
#Get the Number of Correct
#numCorrect <- length(which(CorrectWrong))
#print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
#accuracy <- numCorrect/dim(testData)[1]
#print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData)
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData)
#Compare the true labels of the
#testing instances with the predictions
CorrectWrong <- (predictions==testData[,28])
#Get the Correct (i.e. TRUE above)
which(CorrectWrong)
#Get the Number of Correct
#numCorrect <- length(which(CorrectWrong))
#print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
#accuracy <- numCorrect/dim(testData)[1]
#print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData,type="class")
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData)
#Compare the true labels of the
#testing instances with the predictions
CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
which(CorrectWrong)
#Get the Number of Correct
#numCorrect <- length(which(CorrectWrong))
#print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
#accuracy <- numCorrect/dim(testData)[1]
#print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-rpart(formula=InvType~.,data=trainData,type="class")
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData)
#Compare the true labels of the
#testing instances with the predictions
CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
which(CorrectWrong)
#Get the Number of Correct
#numCorrect <- length(which(CorrectWrong))
#print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
#accuracy <- numCorrect/dim(testData)[1]
#print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData)
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData,type="class")
#Compare the true labels of the
#testing instances with the predictions
CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
which(CorrectWrong)
#Get the Number of Correct
#numCorrect <- length(which(CorrectWrong))
#print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
#accuracy <- numCorrect/dim(testData)[1]
#print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
set.seed(100)
#create the training dataset
#get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
##Number of instances in trainData
print(dim(trainData)[1])
#Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
##Number of instances in trainData
print(dim(testData)[1])
##Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData)
##Visualize the Decision Tree in text form
##dt
##Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
##Get the predictions
predictions <- predict(dt,testData,type="class")
#Compare the true labels of the
#testing instances with the predictions
CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
#which(CorrectWrong)
#Get the Number of Correct
numCorrect <- length(which(CorrectWrong))
print(paste("Nombre d'instances correctement classées : ", numCorrect))
#Get the accuracy, i.e. the % of correct
accuracy <- numCorrect/dim(testData)[1]
print(paste("Pourcentage d'instances bien classées : ", accuracy))
## Get average number of correct / accuracy
##AverageCorrect = AverageCorrect / 5
##AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
## TP Decision Trees
## setwd("F:/School/HEG/Data-mining/TPs/Final project")
## colClassesParams <- c("numeric", "character", rep("numeric", 7), rep("character", 15), rep("numeric", 3), "character")
## myData <- read.table("investing_program_prediction_data.csv", header=TRUE, sep=",", colClasses=colClassesParams)
## datasetName <- "investing_program_prediction_data.csv"
##Exact call
## runAnalysis(datasetName, colClassesParams, rpart, 28)
runAnalysis <- function(datasetName,colClassesParams, methodName, ClassAttributeIndex){
## rpart
library(rpart)
##Cette option permet d'afficher les valeurs réelles
##au lieu des notations scientifiques
options(scipen=999)
## Read data
dataset<- read.table(datasetName,header=T,sep=",", colClasses=colClassesParams)
ClassAttributeName <- names(dataset)[ClassAttributeIndex]
## Set seed to get same sequence of random values
set.seed(100)
## Total for number of correct / accuracy
## To get average
AverageCorrect = 0
AverageAccuracy = 0
i = 0
while(i < 5){
## Create the training dataset
## get 2/3 of the data for training
trainIndex <- sample(1:dim(dataset)[1],size=(2/3)*dim(dataset)[1])
trainData <- dataset[trainIndex,]
## Number of instances in trainData
print(dim(trainData)[1])
## Creating the testing data
#(actually the rest of the data)
testData <- dataset[-trainIndex,]
## Number of instances in trainData
print(dim(testData)[1])
## Train a Decision Tree on trainData
dt<-methodName(formula=InvType~.,data=trainData)
## Visualize the Decision Tree in text form
##dt
## Visualize the Decision Tree using a plot
##plot(dt,compress=T,uniform=T,margin=0.2)
##text(dt,digits=3,use.n=T)
## Get the predictions
predictions <- predict(dt,testData,type="class")
## Compare the true labels of the
## testing instances with the predictions
CorrectWrong <- (predictions==testData[,ClassAttributeIndex])
#Get the Correct (i.e. TRUE above)
#which(CorrectWrong)
## Get the Number of Correct
numCorrect <- length(which(CorrectWrong))
print(paste("Nombre d'instances correctement classées : ", numCorrect))
## Get the accuracy, i.e. the % of correct
accuracy <- numCorrect/dim(testData)[1]
print(paste("Pourcentage d'instances bien classées : ", accuracy))
}
## Get average number of correct / accuracy
AverageCorrect = AverageCorrect / 5
AverageAccuracy = AverageAccuracy / 5
## Display average number of correct / accuracy
##print(paste("Moyenne d'instances correctement classés : ", AverageCorrect))
##print(paste("Moyenne de précision pour l'algorithme", as.character(substitute(methodName)), " : ", AverageAccuracy))
}
runAnalysis(datasetName, colClassesParams, rpart, 28)
